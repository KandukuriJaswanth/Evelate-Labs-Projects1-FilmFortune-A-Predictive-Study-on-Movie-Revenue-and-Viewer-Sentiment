# -*- coding: utf-8 -*-
"""FilmFortune: A Predictive Study on Movie Revenue and Viewer Sentiment

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1GmkTrzA2-oV7X3CtKo3DRUXirxh1HUAn
"""

!pip install xlsxwriter

#!/usr/bin/env python3
"""
Movie Success Prediction + Sentiment Analysis
- Sentiment from plot_keywords using NLTK VADER
- Regression using budget, imdb_score, sentiment to predict gross
- Outputs Excel report + bar plot
"""
import pandas as pd
import numpy as np
#  NLP: make sure VADER is ready
import nltk
try:
    nltk.data.find("sentiment/vader_lexicon.zip")
except LookupError:
    nltk.download("vader_lexicon")
from nltk.sentiment.vader import SentimentIntensityAnalyzer
#  ML & metrics
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
import sklearn
from packaging import version              # to check sklearn version
#  Viz
import matplotlib.pyplot as plt
import seaborn as sns

# Run this only once if VADER not downloaded
nltk.download("vader_lexicon")

# Load your movie dataset
df = pd.read_csv("/content/drive/MyDrive/movie_metadata.csv")
df

# Basic Metrics
print(df.shape)
print(df.columns)

df.info()
df.describe(include="all")

# Data Cleaning
df.isna().sum()

# 1. Handle missing categorical values
df["color"] = df["color"].fillna(df["color"].mode()[0])
df["director_name"] = df["director_name"].fillna("Unknown")
df["actor_1_name"] = df["actor_1_name"].fillna("Unknown")
df["actor_2_name"] = df["actor_2_name"].fillna("Unknown")
df["actor_3_name"] = df["actor_3_name"].fillna("Unknown")
df["content_rating"] = df["content_rating"].fillna(df["content_rating"].mode()[0])
df["plot_keywords"] = df["plot_keywords"].fillna("Unknown")
df["language"] = df["language"].fillna(df["language"].mode()[0])
df["country"] = df["country"].fillna(df["country"].mode()[0])

# 2. Handle missing numeric values with median
median_fill_cols = [
    "num_critic_for_reviews",
    "duration",
    "num_user_for_reviews",
    "title_year"
]
for col in median_fill_cols:
    df[col] = df[col].fillna(df[col].median())

# 3. Fill other numeric columns with 0
zero_fill_cols = [
    "director_facebook_likes",
    "actor_1_facebook_likes",
    "actor_2_facebook_likes",
    "actor_3_facebook_likes",
    "cast_total_facebook_likes",
    "facenumber_in_poster"
]
for col in zero_fill_cols:
    df[col] = df[col].fillna(0)

# Aspect ratio: Fill with mode
df["aspect_ratio"] = df["aspect_ratio"].fillna(df["aspect_ratio"].mode()[0])

# 4. Drop rows where budget or gross is missing
df = df.dropna(subset=["budget", "gross"])

# 5. Convert to correct data types
df["budget"] = df["budget"].astype(float)
df["gross"] = df["gross"].astype(float)

# 6. Save cleaned dataset (optional)
df.to_csv("cleaned_movie_metadata.csv", index=False)
print(" Data cleaning complete. Final shape:", df.shape)

# Verifying the Data Cleaning Process
df.isna().sum()

#  STEP 2: Sentiment Analysis on plot_keywords
# Initialize VADER sentiment analyzer
sid = SentimentIntensityAnalyzer()

# Apply sentiment score to plot_keywords
df["Sentiment_Score"] = df["plot_keywords"].fillna("").str.replace("|", " ").apply(
    lambda x: sid.polarity_scores(x)["compound"]
)

# STEP 3: Build Regression Model to Predict Gross
# Select features and target
X = df[["budget", "imdb_score", "Sentiment_Score"]]
y = df["gross"]

# Split the data
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# Train Linear Regression model
model = LinearRegression()
model.fit(X_train, y_train)

# Predict and evaluate
df.loc[:, "Predicted_Gross"] = model.predict(X)
y_pred_test = model.predict(X_test)
r2 = r2_score(y_test, y_pred_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred_test))  # ‚àöMSE instead of squared=False

# STEP 4: Create Pivot Tables for Analysis
df["Main_Genre"] = df["genres"].str.split("|").str[0]

# Genre-wise sentiment
genre_sentiment = (
    df.groupby("Main_Genre")["Sentiment_Score"]
      .agg(["mean", "count"])
      .rename(columns={"mean": "Avg_Sentiment", "count": "Movie_Count"})
      .sort_values("Avg_Sentiment", ascending=False)
)

# Revenue summaries by genre
genre_gross_pivot = df.pivot_table(
    values="gross", index="Main_Genre", aggfunc=["mean", "sum", "count"]
)

# ‚úÖ  IMDB rating vs Budget & Gross
rating_budget_pivot = df.pivot_table(
    values=["budget", "gross"], index="imdb_score", aggfunc="mean"
)

# step-5
# üìä Plot 1: Sentiment Score by Genre (Displayed)
plt.figure(figsize=(10, 6))
sns.barplot(
    data=genre_sentiment.reset_index(),
    x="Avg_Sentiment",
    y="Main_Genre",
    hue="Main_Genre",
    dodge=False,
    palette="viridis",
    legend=False
)
plt.title("Average Sentiment Score by Genre")
plt.xlabel("Avg Sentiment (compound)")
plt.ylabel("Main Genre")
plt.tight_layout()
plt.show()
plt.close()

# üìä Plot 2: IMDB Score vs Average Gross
plt.figure(figsize=(4, 4))
sns.lineplot(
    data=rating_budget_pivot.reset_index(),
    x="imdb_score",
    y="gross",
    marker="o",
    color="teal"
)
plt.title("IMDB Score vs Average Gross Revenue")
plt.xlabel("IMDB Score")
plt.ylabel("Average Gross")
plt.grid(True)
plt.tight_layout()
plt.show()
plt.close()

# üìä Plot 3: Budget vs Gross (Scatter)
plt.figure(figsize=(4, 4))
sns.scatterplot(
    data=df,
    x="budget",
    y="gross",
    alpha=0.6,
    color="purple"
)
plt.title("Budget vs Gross Revenue")
plt.xlabel("Budget")
plt.ylabel("Gross Revenue")
plt.tight_layout()
plt.show()
plt.close()

#  üìä Plot 4 Create Sentiment Bar Plot by Genre (future-safe)
plt.figure(figsize=(5, 6))
sns.barplot(
    data=genre_sentiment.reset_index(),
    x="Avg_Sentiment",
    y="Main_Genre",
    hue="Main_Genre",
    dodge=False,
    palette="viridis",
    legend=False
)
plt.title("Average Sentiment Score by Genre")
plt.xlabel("Avg Sentiment (compound)")
plt.ylabel("Main Genre")
plt.tight_layout()
plt.show()
plt.close()

try:
    # Additional pivot tables
    country_pivot = df.pivot_table(
        values="gross", index="country", aggfunc=["mean", "sum", "count"]
    ).sort_values(("mean", "gross"), ascending=False)

    director_pivot = df.pivot_table(
        values=["imdb_score", "gross"],
        index="director_name",
        aggfunc="mean"
    ).sort_values("gross", ascending=False).head(20)

    content_rating_pivot = df.pivot_table(
        values=["budget", "gross"],
        index="content_rating",
        aggfunc="mean"
    )
    correlation_matrix = df[["gross", "budget", "imdb_score", "Sentiment_Score"]].corr()

    # Excel export with all insights
    with pd.ExcelWriter("Movie_Success_Predictions.xlsx", engine="xlsxwriter") as writer:
        df.to_excel(writer, sheet_name="Data_Predictions", index=False)
        genre_sentiment.to_excel(writer, sheet_name="Genre_Sentiment_Pivot")
        genre_gross_pivot.to_excel(writer, sheet_name="Genre_Gross_Pivot")
        rating_budget_pivot.to_excel(writer, sheet_name="Rating_vs_Budget_Gross")

        pd.DataFrame({
            "Metric": ["R2 Score", "RMSE"],
            "Value": [r2, rmse]
        }).to_excel(writer, sheet_name="Model_Summary", index=False)

        df.describe(include="all").to_excel(writer, sheet_name="Descriptive_Stats")
        country_pivot.to_excel(writer, sheet_name="Country_vs_Gross")
        director_pivot.to_excel(writer, sheet_name="Top_Directors")
        content_rating_pivot.to_excel(writer, sheet_name="Rating_vs_Gross")
        correlation_matrix.to_excel(writer, sheet_name="Correlation_Matrix")

    print("‚úÖ Excel file with all sheets saved successfully.")

except Exception as e:
    print("‚ùå Error occurred while saving Excel file:", str(e))

